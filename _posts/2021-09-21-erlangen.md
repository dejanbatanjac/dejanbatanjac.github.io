---
published: false
layout: post
title: Erlangen
permalink: /erlangen
---

If you ever wondered what is regularization, it's a Occam's razor principle that "the simplest explanation is usually the best one."

This principle is know as *the law of parsimony*.







Geometric deep learning is the synonym or almost the synonym for the GNN (Graph Neural Networks).

We can ask what are graph convolutions?

What is the prior in GNN?

What is blueprint?

What tractable means in Bayesian sense?

## What is geometric prior

The geometric prior encourages models to stay in a legal shape-space. We de- scribe an implementation of the method using m-reps and present results showing that the method is accurate and yields models suitable for statistical analysis. Deformable Models We desire a statistical model for a population of training.



## What is local receptive filed

The _receptive field_ is the region in the input space that a particular CNN's feature is looking at. A receptive field of a feature can be described by its center location and its size.

The local receptive field is a defined segmented area that is occupied by the content of input data that a neuron within a convolutional layer is exposed to during the process of convolution. The LeNet paper introduced the first use case of the utilization of the convolutional neural network for character recognition


In mathematics, the Erlangen program is a method of characterizing geometries based on group theory.

All various geometries known could be defined by an appropriate choice of symmetry transformations, formalized using the language of group theory.

What is standard model in modern Physics?

That would be the model of all the know forces except the gravity, that can explain the rules of the universe.





Erlangen Programme mindset.

_Grid graphs_ are the class of graphs where vertices are present on the lattice points of a two-dimensional grid, and an edge can occur between a vertex and its immediate horizontal or vertical neighbor only.


A lattice graph, mesh graph, or grid graph, is a graph whose drawing, embedded in some Euclidean space Rn, forms a regular tiling.

This type of graph may more shortly be called just a lattice, mesh, or grid.



For instance, Euclidean geometry is concerned
with lengths and angles, because these properties are preserved by the
group of Euclidean transformations (rotations and translations), while affine geometry studies parallelism, which is preserved by the group of affine transformations. 

The relation between these geometries is immediately
apparent when considering the respective groups, because the Euclidean group is a subgroup of the affine group, which in turn is a subgroup of the
group of projective transformations.


Remarkably, the essence of deep learning is built from two simple algorithmic principles: first, the notion of representation or feature learning, whereby adapted, often hierarchical, features capture the appropriate notion of regularity for each task, and second, learning by local gradient-descent, typically implemented as backpropagation.


Exploiting the known symmetries of a large system is a powerful and classical remedy against the curse of dimensionality.

self-supervised learning, generative modelling, or reinforcement learning

> Self-supervised machine is simplification of complex tasks into simple ones to arrive at a desired output despite the lack of labeled datasets.

> Generative modeling is used in unsupervised machine learning as a means to describe phenomena in data, enabling computers to understand the real world.

> Reinforcement learning is a machine learning training method based on rewarding desired behaviors and/or punishing undesired ones. In general, it is learning through trial and error.


General case:

$$ {M! \over (M-k)!}$$

Deep sets are:

$$ {M! \over (M-1)!}$$


Self attention is $k=2$ case:

$$ {M! \over (M-2)!}$$



 Lipschitz function

 Let F(x) be an upper semi-continuous function of x, and that F(x) is a closed, convex set for all x. Then F is one-sided Lipschitz if. for some C and for all x1 and x2.

 Lipschitz continuity, named after German mathematician Rudolf Lipschitz, is a strong form of uniform continuity for functions.


 Furthermore, symmetries are always in-
vertible, and the inverse is also a symmetry. This shows that the collection
of all symmetries form an algebraic object known as a group.

In mathematics, an automorphism is an isomorphism from a mathematical object to itself. It is, in some sense, a symmetry of the object, and a way of mapping the object to itself while preserving all of its structure. The set of all automorphisms of an object forms a group, called the automorphism group.
---
published: true
layout: post
title: Training optimizers with momentum
---
The optimizer is a unit that improves neural network parameters based on gradients.

Often we need to predict moving trends for our gradients, which is a very complex process, but usually involves analyzing the mean for each gradient of every parameter.

Since there may be millions or even hundred millions of parameters in our neural network model we need to be efficient.

For many applications a simple moving average (SMA) that calculates the progressive mean is used.

$$ {1\over n } \sum_{i=1}^n y_i  $$

This would be inefficient from the computational standpoint when working with gradients. Luckily there are [other techniques](https://en.wikipedia.org/wiki/Moving_average).

The exponential moving average EMA is something optimizers frequently use.

EMA looks like this:

$$z_{i+1} = \beta * y_i + (1-\beta) * y_{i+1}$$

I will show two data models in PyTorch to explain EMA.

## Model 1: Normal distribution 

Let's consider this normal data distribution for `y` with offset `0.3`.
```
import torch
x = torch.linspace(-4,4,200)
y=torch.randn(200)+0.3
plt.scatter(x,y)
plt.show()
```

![IMG](/images/momentum1.png)

If we take the next equation to calculate the moving average `z`:

$$z_{i+1} = \beta * y_i + (1-\beta) * y_{i+1}$$

Depending on momentum `$\beta$` we may have different results.

![IMG](/images/momentum2.gif)

In the upper equation we should notice the momentum need to be carefully set depending on what we try to achieve.

If we would like to fit almost any data point then the smaller the momentum the better.

If we would try to be less bumpy we would consider 0.9 for the momentum.

Probable for random data momentum has no sense. This is why we will examine some function next.


## Model 2: Data distribution is `cos` function with some noise

Let's define our data:

```
x = torch.arange(-3.,3.,step=0.05)
x = torch.linspace(-3,3,100)
yo = torch.cos(x) #orig
y = yo + 0.5*torch.rand(yo.size())-0.25
plt.scatter(x,y, alpha=0.5)
plt.plot(x,yo)
plt.show()
```

![IMG](/images/momentum3.png)

The tiny blue line is a helper, what we care about is the scatter plot, where we will consider the get the exponentially moving average.

$$z_{i+1} = \beta * y_i + (1-\beta) * y_{i+1}$$


![IMG](/images/momentum4.gif)

Check out that if our momentum is too small like `0.01` we will be far away from the original cosine function.

...
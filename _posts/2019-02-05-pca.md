---
published: false
---
## ПЦА

ПЦА (Principal Component Analysis) или метода анализе главних компоненти је један од главних начина за смањење димензије података губитком најмање количине информација. 

Изумио га је Карл Пирсон 1901 године. 

### Статистика

Цео предмет статистике заснива се на идеји да имате "велики" скуп података, и желите анализирати односе елемената тог скупа.

### Стандардно одступање (девијација)

Она нам говори, колико у просеку елементи скупа одступају од аритметичке средине скупа. Означава се грчким словом сигма, σ. Формула за њено израчунавање је: 

![std](https://wikimedia.org/api/rest_v1/media/math/render/svg/cc45b72e1fd6a3de3ec4977f42367f104f57583f)
 

### Варијанса

Стандардно одступање је квадратни корен варијансе. 

На пример, савршена коцка за игру увек даје један од 6 исхода. Средња вредност очекивог исхода је:  (1 + 2 + 3 + 4 + 5 + 6)/6 = 3.5

Апсолутна одступања од средље вредности су:  2.5; 1.5; 0.5; 0.5; 1.5; 2.5
Где је 3.5 − 1 = 2.5, одступање коцке за исход 1.
 
Варијанса је средња вредност једнаковероватних квадрата одступања: 
(2.52 + 1.52 + 0.52 + 0.52, 1.52, 2.52)/6 = 17.5/6 ≈ 2,9 

Очекивана стандардна девијација је σ ≈ 1.71


### Сопствене вредности 

Као што знате, ако за квадратну матрицу `А` помножену вектором `v` важи

### Av = λv

где је `λ` сопствена вредност матрице и може да буде рационалан, ирационалан или комплексан број.

Сопствене вредности иду у пару са сопственим векторима и најчеће се израчунавају заедно. Ево примера у numpy.

~~~
import numpy as np
from numpy import linalg as LA
a = np.matrix('2 3; 2 1')  # рационалан број
b = np.matrix('0 2; 1 0')  # ирационалан број
c = np.matrix('0 -1; 1 0') # комплексан број


evalues, evectors = LA.eig(a)
print(evalues, evectors)
evalues, evectors = LA.eig(b)
print(evalues, evectors)
evalues, evectors = LA.eig(c)
print(evalues, evectors)
~~~
Даће резултат:

~~~
[ 4. -1.] 
 [[ 0.83205029 -0.70710678]
 [ 0.5547002   0.70710678]] 

[ 1.41421356 -1.41421356] 
 [[ 0.81649658 -0.81649658]
 [ 0.57735027  0.57735027]] 

[0.+1.j 0.-1.j] 
 [[0.70710678+0.j         0.70710678-0.j        ]
 [0.        -0.70710678j 0.        +0.70710678j]] 
~~~

### Коваријанса и матрица коваријансе

Многи скупови података имају само једну димензију. Рецимо, висина људи.
Постоје и такви скупови који имају више од једне димензије и циљ статистичке анализе је да се одреди да ли постоји неки однос између димензија.

На пример, нека наши подаци представљају висину људи и животно доба. Онда бисмо могли да изведемо
статистичку анализу да утврдимо да ли постоји међу утицај.

Стандардна девијација и варијанса примењују се на подататке у истој димензији. Ако скуп има две или више димензија може се израчунавати стандардна девијација за сваку димензију скупа независно. 

Међутим, корисно је имати и меру како би се сазнало како димензије утичу једна на другу. Коваријанса је таква мера.

Коваријансаца је однос између две димензије. Ако израчунамо коваријанцу између једне димензије у односу на ту димензију добијамо варијансу.

Формула за израчунавање коваријансе изгледа овако.

Ако је коваријанса 0 онда не постоји зависност између димензија. Ако је коваријанса позитивна онда су димензије у корелацији (значи да раст или опадање параметара једне димензије утиче на раст и опадање параметара друге димензије). Ако је коваријанса негативна, онда је тај утицај супротан - антикирелација.

За скуп који има више димензија користан начин да добијете све могуће вредности коваријансе између свих различитих димензија је да из израчунамо и ставимо у матрицу. Ова матрица се назива матрица коваријансе.

Пример:
Посматрајмо матрицу која садржи узорковања за три променљиве: x0, x1 and x2 чије вредности се налазе у редовима. Имамо пет узорковања.

~~~
import numpy as np
X = np.array([ [0.1, 0.3, 0.4, 0.8, 0.9],
               [3.2, 2.4, 2.4, 0.1, 5.5],
               [10., 8.2, 4.3, 2.6, 0.9]
             ])

print( np.cov(X) )
~~~
Кораријанса ће бити `3*3` матрица:
~~~
[[ 0.115   0.0575 -1.2325]
 [ 0.0575  3.757  -0.8775]
 [-1.2325 -0.8775 14.525 ]]
 ~~~
 
Иако се вредности матрице коваријанси не могу лако интерпретирати јер зависе од величине индивидуалних узорковања која могу да буду различита за различите променљиве, јасно је да:

* постоји антикоречација између `x0` и `x2` (`C02=−1.2325`: када једна расте друга опада).
* између `x0` и `x1` не постоји јака корелација (`C01=0.0575`).



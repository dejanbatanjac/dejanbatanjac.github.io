---
published: false
---
## What is GPT-2?

OpenAI came out with a new language model that automatically synthesizes text, called GPT-2.
Here is the model [repo](https://github.com/openai/gpt-2). In simple words the model predicts the next word. Nothing fancy. But it can do that reasonably well, in fact so well, that humans cannot spot the difference.

Why it is called GPT? GPT stands for General Purpose Technology. At first you may ask why it is called like that since it is just the next word predictor?

It came out that if you can predict the next word you can do many other things just based on that.

Almost the whole NLP (Neuro-Linguistic Programming) or shorter LP (Linguistic Programming) is covered with that "simple" model.

Here is what NLP can do (ad hock):

- Generate text
- Reading comprehension
- Annotate a sentence
- Semantic role labeling and parsing
- Named entity recognition
- Constituency parsing
- Dependency parsing
- Information extraction
- Annotate a passage
- Coreference resolution
- Answer a question
- Text to SQL

More or less 90% of things mentioned you gain with the GPT-2. 


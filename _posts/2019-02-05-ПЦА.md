---
published: true
---

ПЦА (Principal Component Analysis) или метода анализе главних компоненти је један математички апарат који посматра податке (узорке) и изводи закључке о мођусобном утицају података. 

Често се овај модел анализе користи за смањење димензије података губитком најмање количине информација. 


### Статистика

Цео предмет статистике заснива се на идеји да имате скуп података, и да желите анализирати односе елемената тог скупа.

### Стандардно одступање (девијација)

Она нам говори, колико у просеку елементи скупа одступају од аритметичке средине скупа. Означава се грчким словом сигма, σ. Формула за њено израчунавање је: 

$\sigma = \displaystyle \sqrt{ \frac1 N \displaystyle \sum_{i=1}^N (x_i - \mu )}$ 
 

### Варијанса

Стандардно одступање је квадратни корен варијансе. 

На пример, мерили смо појаву и добили 6 исхода: 1, 2, 3, 4, 5, 6: . Аритметичка средина очекивог исхода је:  (1 + 2 + 3 + 4 + 5 + 6)/6 = 3.5

Апсолутна одступања од средње вредности су:  2.5; 1.5; 0.5; 0.5; 1.5; 2.5,
где је 3.5 − 1 = 2.5, одступање за мерање при исходу 1.
 
Варијанса је средња вредност једнаковероватних квадрата одступања: 
(2.52 + 1.52 + 0.52 + 0.52, 1.52, 2.52)/6 = 17.5/6 ≈ 2,9 

Очекивана стандардна девијација је σ ≈ 1.71
Она се може рачунати помоћу пакета Python Numpy:

~~~python
import numpy as np
sigma = np.std([1, 2, 3, 4, 5, 6])
print(sigma)
# 1.707825127659933
~~~


### Сопствене вредности 

Као што знате, ако за квадратну матрицу `А` помножену вектором `v` важи

### Av = λv

где је `λ` сопствена вредност матрице и може да буде рационалан, ирационалан или комплексан број.

Сопствене вредности иду у пару са сопственим векторима и најчеће се израчунавају заједно. Ево примера у Пајтону.

~~~python
import numpy as np
from numpy import linalg as la
a = np.matrix('2 3; 2 1')  # рационалан број
b = np.matrix('0 2; 1 0')  # ирационалан број
c = np.matrix('0 -1; 1 0') # комплексан број


evalues, evectors = la.eig(a)
print(evalues, evectors)
evalues, evectors = la.eig(b)
print(evalues, evectors)
evalues, evectors = la.eig(c)
print(evalues, evectors)
~~~
Даће резултат:

~~~
[ 4. -1.] 
 [[ 0.83205029 -0.70710678]
 [ 0.5547002   0.70710678]] 

[ 1.41421356 -1.41421356] 
 [[ 0.81649658 -0.81649658]
 [ 0.57735027  0.57735027]] 

[0.+1.j 0.-1.j] 
 [[0.70710678+0.j         0.70710678-0.j        ]
 [0.        -0.70710678j 0.        +0.70710678j]] 
~~~

Овде треба додати да приликом множења матрице важе иста правила као и за множење скалара. 

Уколико матрица учествује у рекурзивном процесу где се множи са собом и сопствене вредности се множе са собом.


```python
import numpy as np
from numpy import linalg as la
a = np.matrix('2 3; 2 1')  # рационалан број
evalues, evectors = la.eig(a)
print(evalues, evectors)
a2 = np.dot(a,a)
evalues, evectors = la.eig(a2)
print(evalues, evectors)
```

Резултат:
```
[ 4. -1.] [[ 0.83205029 -0.70710678]
 [ 0.5547002   0.70710678]]
[16.  1.] [[ 0.83205029 -0.70710678]
 [ 0.5547002   0.70710678]]
```

Уколико се овај процес понавља сопствене вредности експоненционално расту и процеси постају нестабилни.

Циљ свих инжењерских процеса је да доминантне сопствене вредности регулишемо. То се постиже или квалитетним иницијализацијама или регулационим процесима а један од њих је нормализација.


### Коваријанса и матрица коваријансе

Многи скупови података имају само једну димензију. Рецимо, висина људи. Постоје и такви скупови који имају више од једне димензије и циљ статистичке анализе је да се одреди да ли постоји неки однос између димензија.

На пример, нека наши подаци представљају висину људи и животно доба. Одатле можемо да изведемо статистичку анализу и утврдимо постоји ли међу-утицај.

Стандардна девијација и варијанса примењују се на подататке у истој димензији. Ако скуп има две или више димензија може се израчунавати стандардна девијација за сваку димензију скупа независно. 

Међутим, корисно је имати и меру како би се сазнало како димензије утичу једна на другу. Коваријанса је таква мера.

Коваријанса је однос између две димензије. Ако израчунамо коваријансу између једне димензије у односу на ту димензију добијамо варијансу.

Формула за израчунавање коваријансе изгледа овако:

$cov(X,Y) = \frac 1 n \displaystyle \sum_{i=1}^n (x_i - E(X))(y_i-E(Y))$, 

где су $X$ i $Y$ стохастичке променљиве, а $E(X)$ и $E(Y)$ срдње вредности или очекиване вредности.


Ако је коваријанса 0 онда не постоји зависност између димензија. Ако је коваријанса позитивна онда су димензије у корелацији (значи да раст или опадање параметара једне димензије утиче на раст и опадање параметара друге димензије). Ако је коваријанса негативна, онда је тај утицај супротан - антикирелација.

За скуп који има више димензија користан начин да добијете све могуће вредности коваријансе између свих различитих димензија је да из израчунамо и ставимо у матрицу. Ова матрица се назива матрица коваријансе.

Пример:
Посматрајмо матрицу која садржи узорковања за три променљиве: x0, x1 and x2 чије вредности се налазе у редовима. Имамо пет узорковања.

~~~python
import numpy as np
X = np.array([ [0.1, 0.3, 0.4, 0.8, 0.9],
               [3.2, 2.4, 2.4, 0.1, 5.5],
               [10., 8.2, 4.3, 2.6, 0.9]
             ])

print( np.cov(X) )
~~~
Коваријанса ће бити `3*3` матрица:
~~~
[[ 0.115   0.0575 -1.2325]
 [ 0.0575  3.757  -0.8775]
 [-1.2325 -0.8775 14.525 ]]
 ~~~
 
Иако се вредности матрице коваријанси не могу лако интерпретирати јер зависе од величине индивидуалних узорковања која могу да буду различита за различите променљиве, јасно је да:

* постоји негативна корелација између `x0` и `x2` (`C02=−1.2325`: када једна расте друга опада).
* између `x0` и `x1` не постоји јака корелација (`C01=0.0575`).

На крају да напоменемо, да модели односно димензије матрице често морају да се мењају да би боље представили проблем.

Ако пратимо године старости популације и висину можемо доћи до закључка да од 0-те до 25-те године висина расте односно коваријанса је већа од 0, док је за године после 25 коваријанса мања од 0. 

У случају када посматрамо висину и старост популације могли бисмо да направимо два модела један који важи за особе млађе од 25 и онај за особе старије од 25 година.

Ипак, статистичар ретко користи коваријансу да покаже међу-зависности већ њој сличну меру **корелацију**.



